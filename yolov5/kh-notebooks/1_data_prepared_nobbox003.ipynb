{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9c4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "import sys\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "from IPython.display import display, HTML\n",
    "from matplotlib import animation, rc\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../input/tensorflow-great-barrier-reef')\n",
    "rc('animation', html='jshtml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112d33e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Error parsing requirements for toolz: [Errno 2] No such file or directory: '/data/kunhao/anaconda/envs/pytorch-37/lib/python3.7/site-packages/toolz-0.11.1.dist-info/METADATA'\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -qU bbox-utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a74235e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check https://github.com/awsaf49/bbox for source code of following utility functions\n",
    "from bbox.utils import coco2yolo, coco2voc, voc2yolo\n",
    "from bbox.utils import draw_bboxes, load_image\n",
    "from bbox.utils import clip_bbox, str2annot, annot2str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4aeb0b",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLD      = 1\n",
    "DIM       = 1280\n",
    "RANDOM_SEED  = 42\n",
    "NOBBOX = 0.03\n",
    "SOURCE_DIR  = '../input/tensorflow-great-barrier-reef/'\n",
    "DATA_DIR = '../input/yolov5_fold1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3160b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Path(DATA_DIR) / \"images/train\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(DATA_DIR) / \"images/val\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(DATA_DIR) / \"labels/train\").mkdir(parents=True, exist_ok=True)\n",
    "(Path(DATA_DIR) / \"labels/val\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014e1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c6f6d",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6444983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d086548dad45bea6ca547b629a0acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No BBox: 79.07% | With BBox: 20.93%\n"
     ]
    }
   ],
   "source": [
    "# Train Data\n",
    "df = pd.read_csv(f'{SOURCE_DIR}train.csv')\n",
    "df['old_image_path'] = f'{SOURCE_DIR}train_images/video_'+df.video_id.astype(str)+'/'+df.video_frame.astype(str)+'.jpg'\n",
    "df['annotations'] = df['annotations'].apply(eval)\n",
    "df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\n",
    "data = (df.num_bbox>0).value_counts(normalize=True)*100\n",
    "print(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb273de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nobbox images\n",
    "df['num_annotations'] = df['annotations'].apply(len)\n",
    "\n",
    "sub1 = df.loc[df.num_annotations > 0].copy()\n",
    "sub2 = df.loc[df.num_annotations == 0].copy()\n",
    "\n",
    "#sub2 = sub2.sample(frac=NOBBOX, random_state=RANDOM_SEED)\n",
    "df = pd.concat([sub1, sub2], axis=0)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "738fe18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_imgsize(row):\n",
    "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "    return row\n",
    "\n",
    "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
    "          for idx in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f083374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a29ac23fdd84e6ea94f2e9ca4b6187b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['bboxes'] = df.annotations.progress_apply(get_bbox)\n",
    "df['width']  = 1280\n",
    "df['height'] = 720"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6c555e",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4e2ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = pd.read_csv(\"../input/cross-validation/train-5folds.csv\")\n",
    "df = df.merge(folds[['image_id', 'fold']], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f938c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fold'] = df['fold'].apply(lambda x: 'train' if x != FOLD else 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cafa2460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train    19471\n",
       "val       4030\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61971125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_path'] = f'{DATA_DIR}'+ 'images/'+ df.fold + '/' + df.image_id+'.jpg'\n",
    "df['label_path'] = f'{DATA_DIR}'+ 'labels/'+ df.fold + '/' + df.image_id+'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e232dbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(DATA_DIR + \"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf8dce5",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17517fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de76f2518a3496a9f7295b0743aff3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 18582\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "all_bboxes = []\n",
    "bboxes_info = []\n",
    "for row_idx in tqdm(range(df.shape[0])):\n",
    "    row = df.iloc[row_idx]\n",
    "    image_height = row.height\n",
    "    image_width  = row.width\n",
    "    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n",
    "    num_bbox     = len(bboxes_coco)\n",
    "    names        = ['cots']*num_bbox\n",
    "    labels       = np.array([0]*num_bbox)[..., None].astype(str)\n",
    "    ## Create Annotation(YOLO)\n",
    "    with open(row.label_path, 'w') as f:\n",
    "        if num_bbox<1:\n",
    "            annot = ''\n",
    "            f.write(annot)\n",
    "            cnt+=1\n",
    "            continue\n",
    "        bboxes_voc  = coco2voc(bboxes_coco, image_height, image_width)\n",
    "        bboxes_voc  = clip_bbox(bboxes_voc, image_height, image_width)\n",
    "        bboxes_yolo = voc2yolo(bboxes_voc, image_height, image_width).astype(str)\n",
    "        all_bboxes.extend(bboxes_yolo.astype(float))\n",
    "        bboxes_info.extend([[row.image_id, row.video_id, row.sequence]]*len(bboxes_yolo))\n",
    "        annots = np.concatenate([labels, bboxes_yolo], axis=1)\n",
    "        string = annot2str(annots)\n",
    "        f.write(string)\n",
    "print('Missing:',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dec36e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df23e5c69b354b85ad14cc2e1cdc07ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23501 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_copy(row):\n",
    "    shutil.copyfile(row.old_image_path, row.image_path)\n",
    "    return\n",
    "\n",
    "\n",
    "image_paths = df.old_image_path.tolist()\n",
    "_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(row) for _, row in tqdm(df.iterrows(), total=len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15c7bb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../input/yolov5_fold1/data.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../input/yolov5_fold1/data.yaml\n",
    "\n",
    "path: ../input/yolov5_fold1  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path') 128 images\n",
    "val: images/val  # val images (relative to 'path') 128 images\n",
    "test:  # test images (optional)\n",
    "\n",
    "# Classes\n",
    "nc: 1  # number of classes\n",
    "names: ['cots']  # class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1344814f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt-37-2022",
   "language": "python",
   "name": "pt-37-2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
