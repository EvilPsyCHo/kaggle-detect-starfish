{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedfff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Copy from implement by \n",
    "# https://www.kaggle.com/c/tensorflow-great-barrier-reef/discussion/290083\n",
    "# https://www.kaggle.com/bamps53/competition-metric-implementation?scriptVersionId=81087805\n",
    "\n",
    "# Yolo infer modified from \n",
    "# https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "102951b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 30, 30\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "from ast import literal_eval\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import shutil\n",
    "import sys\n",
    "sys.path.append('../input/tensorflow-great-barrier-reef')\n",
    "import torch\n",
    "from PIL import Image\n",
    "import ast\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc9f8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from norfair import Detection, Tracker\n",
    "\n",
    "# Helper to convert bbox in format [x_min, y_min, x_max, y_max, score] to norfair.Detection class\n",
    "def to_norfair(detects, frame_id):\n",
    "    result = []\n",
    "    for x_min, y_min, x_max, y_max, score in detects:\n",
    "        xc, yc = (x_min + x_max) / 2, (y_min + y_max) / 2\n",
    "        w, h = x_max - x_min, y_max - y_min\n",
    "        result.append(Detection(points=np.array([xc, yc]), scores=np.array([score]), data=np.array([w, h, frame_id])))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3d8f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(row):\n",
    "    row['image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n",
    "    return row\n",
    "\n",
    "def voc2yolo(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n",
    "    \n",
    "    w = bboxes[..., 2] - bboxes[..., 0]\n",
    "    h = bboxes[..., 3] - bboxes[..., 1]\n",
    "    \n",
    "    bboxes[..., 0] = bboxes[..., 0] + w/2\n",
    "    bboxes[..., 1] = bboxes[..., 1] + h/2\n",
    "    bboxes[..., 2] = w\n",
    "    bboxes[..., 3] = h\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def yolo2voc(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    voc  => [x1, y1, x2, y1]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def coco2yolo(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    coco => [xmin, ymin, w, h]\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    \"\"\"\n",
    "    \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    # normolizinig\n",
    "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n",
    "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n",
    "    \n",
    "    # converstion (xmin, ymin) => (xmid, ymid)\n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def yolo2coco(bboxes, image_height=720, image_width=1280):\n",
    "    \"\"\"\n",
    "    yolo => [xmid, ymid, w, h] (normalized)\n",
    "    coco => [xmin, ymin, w, h]\n",
    "    \n",
    "    \"\"\" \n",
    "    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n",
    "    \n",
    "    # denormalizing\n",
    "    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n",
    "    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n",
    "    \n",
    "    # converstion (xmid, ymid) => (xmin, ymin) \n",
    "    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n",
    "    \n",
    "    return bboxes\n",
    "\n",
    "def voc2coco(bboxes, image_height=720, image_width=1280):\n",
    "    bboxes  = voc2yolo(bboxes, image_height, image_width)\n",
    "    bboxes  = yolo2coco(bboxes, image_height, image_width)\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def load_image(image_path):\n",
    "    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "def plot_one_box(x, img, color=None, label=None, line_thickness=None):\n",
    "    # Plots one bounding box on image img\n",
    "    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n",
    "    color = color or [random.randint(0, 255) for _ in range(3)]\n",
    "    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n",
    "    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n",
    "    if label:\n",
    "        tf = max(tl - 1, 1)  # font thickness\n",
    "        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n",
    "        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n",
    "        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n",
    "        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n",
    "\n",
    "def draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, \n",
    "                bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n",
    "     \n",
    "    image = img.copy()\n",
    "    show_classes = classes if show_classes is None else show_classes\n",
    "    colors = (0, 255 ,0) if colors is None else colors\n",
    "    \n",
    "    if bbox_format == 'yolo':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes:\n",
    "            \n",
    "                x1 = round(float(bbox[0])*image.shape[1])\n",
    "                y1 = round(float(bbox[1])*image.shape[0])\n",
    "                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n",
    "                h  = round(float(bbox[3])*image.shape[0]/2)\n",
    "\n",
    "                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(get_label(cls)),\n",
    "                             line_thickness = line_thickness)\n",
    "            \n",
    "    elif bbox_format == 'coco':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes:            \n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                w  = int(round(bbox[2]))\n",
    "                h  = int(round(bbox[3]))\n",
    "\n",
    "                voc_bbox = (x1, y1, x1+w, y1+h)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(cls_id),\n",
    "                             line_thickness = line_thickness)\n",
    "\n",
    "    elif bbox_format == 'voc_pascal':\n",
    "        \n",
    "        for idx in range(len(bboxes)):  \n",
    "            \n",
    "            bbox  = bboxes[idx]\n",
    "            cls   = classes[idx]\n",
    "            cls_id = class_ids[idx]\n",
    "            color = colors[cls_id] if type(colors) is list else colors\n",
    "            \n",
    "            if cls in show_classes: \n",
    "                x1 = int(round(bbox[0]))\n",
    "                y1 = int(round(bbox[1]))\n",
    "                x2 = int(round(bbox[2]))\n",
    "                y2 = int(round(bbox[3]))\n",
    "                voc_bbox = (x1, y1, x2, y2)\n",
    "                plot_one_box(voc_bbox, \n",
    "                             image,\n",
    "                             color = color,\n",
    "                             label = cls if class_name else str(cls_id),\n",
    "                             line_thickness = line_thickness)\n",
    "    else:\n",
    "        raise ValueError('wrong bbox format')\n",
    "\n",
    "    return image\n",
    "\n",
    "def get_bbox(annots):\n",
    "    bboxes = [list(annot.values()) for annot in annots]\n",
    "    return bboxes\n",
    "\n",
    "def get_imgsize(row):\n",
    "    row['width'], row['height'] = imagesize.get(row['image_path'])\n",
    "    return row\n",
    "\n",
    "np.random.seed(32)\n",
    "colors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n",
    "          for idx in range(1)]\n",
    "\n",
    "\n",
    "def decode_annotations(annotaitons_str):\n",
    "    \"\"\"decode annotations in string to list of dict\"\"\"\n",
    "    return literal_eval(annotaitons_str)\n",
    "\n",
    "def load_image_with_annotations(video_id, video_frame, image_dir, annotaitons_str):\n",
    "    img = load_image(video_id, video_frame, image_dir)\n",
    "    annotations = decode_annotations(annotaitons_str)\n",
    "    if len(annotations) > 0:\n",
    "        for ann in annotations:\n",
    "            cv2.rectangle(img, (ann['x'], ann['y']),\n",
    "                (ann['x'] + ann['width'], ann['y'] + ann['height']),\n",
    "                (255, 0, 0), thickness=2,)\n",
    "    return img\n",
    "\n",
    "def draw_predictions(img, pred_bboxes):\n",
    "    img = img.copy()\n",
    "    if len(pred_bboxes) > 0:\n",
    "        for bbox in pred_bboxes:\n",
    "            conf = bbox[0]\n",
    "            x, y, w, h = bbox[1:].round().astype(int)\n",
    "            cv2.rectangle(img, (x, y),\n",
    "                (x+w, y+h),\n",
    "                (0, 255, 255), thickness=2,)\n",
    "            cv2.putText(\n",
    "                img,\n",
    "                f\"{conf:.2}\",\n",
    "                (x, max(0, y-5)),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.5,\n",
    "                (0, 0, 255),\n",
    "                thickness=1,\n",
    "            )\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42955d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_iou(bboxes1, bboxes2, bbox_mode='xywh'):\n",
    "    assert len(bboxes1.shape) == 2 and bboxes1.shape[1] == 4\n",
    "    assert len(bboxes2.shape) == 2 and bboxes2.shape[1] == 4\n",
    "    \n",
    "    bboxes1 = bboxes1.copy()\n",
    "    bboxes2 = bboxes2.copy()\n",
    "    \n",
    "    if bbox_mode == 'xywh':\n",
    "        bboxes1[:, 2:] += bboxes1[:, :2]\n",
    "        bboxes2[:, 2:] += bboxes2[:, :2]\n",
    "\n",
    "    x11, y11, x12, y12 = np.split(bboxes1, 4, axis=1)\n",
    "    x21, y21, x22, y22 = np.split(bboxes2, 4, axis=1)\n",
    "    xA = np.maximum(x11, np.transpose(x21))\n",
    "    yA = np.maximum(y11, np.transpose(y21))\n",
    "    xB = np.minimum(x12, np.transpose(x22))\n",
    "    yB = np.minimum(y12, np.transpose(y22))\n",
    "    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n",
    "    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n",
    "    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n",
    "    iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n",
    "    return iou\n",
    "\n",
    "def f_beta(tp, fp, fn, beta=2):\n",
    "    return (1+beta**2)*tp / ((1+beta**2)*tp + beta**2*fn+fp)\n",
    "\n",
    "def calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th, verbose=False):\n",
    "    gt_bboxes = gt_bboxes.copy()\n",
    "    pred_bboxes = pred_bboxes.copy()\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for k, pred_bbox in enumerate(pred_bboxes): # fixed in ver.7\n",
    "        ious = calc_iou(gt_bboxes, pred_bbox[None, 1:])\n",
    "        max_iou = ious.max()\n",
    "        if max_iou > iou_th:\n",
    "            tp += 1\n",
    "            gt_bboxes = np.delete(gt_bboxes, ious.argmax(), axis=0)\n",
    "        else:\n",
    "            fp += 1\n",
    "        if len(gt_bboxes) == 0:\n",
    "            fp += len(pred_bboxes) - (k + 1) # fix in ver.7\n",
    "            break\n",
    "\n",
    "    fn = len(gt_bboxes)\n",
    "    return tp, fp, fn\n",
    "\n",
    "def calc_is_correct(gt_bboxes, pred_bboxes):\n",
    "    \"\"\"\n",
    "    gt_bboxes: (N, 4) np.array in xywh format\n",
    "    pred_bboxes: (N, 5) np.array in conf+xywh format\n",
    "    \"\"\"\n",
    "    if len(gt_bboxes) == 0 and len(pred_bboxes) == 0:\n",
    "        tps, fps, fns = 0, 0, 0\n",
    "        return tps, fps, fns\n",
    "    \n",
    "    elif len(gt_bboxes) == 0:\n",
    "        tps, fps, fns = 0, len(pred_bboxes), 0\n",
    "        return tps, fps, fns\n",
    "    \n",
    "    elif len(pred_bboxes) == 0:\n",
    "        tps, fps, fns = 0, 0, len(gt_bboxes)\n",
    "        return tps, fps, fns\n",
    "    \n",
    "    pred_bboxes = pred_bboxes[pred_bboxes[:,0].argsort()[::-1]] # sort by conf\n",
    "    \n",
    "    tps, fps, fns = 0, 0, 0\n",
    "    for iou_th in np.arange(0.3, 0.85, 0.05):\n",
    "        tp, fp, fn = calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th)\n",
    "        tps += tp\n",
    "        fps += fp\n",
    "        fns += fn\n",
    "    return tps, fps, fns\n",
    "\n",
    "def calc_f2_score(gt_bboxes_list, pred_bboxes_list, verbose=False):\n",
    "    \"\"\"\n",
    "    gt_bboxes_list: list of (N, 4) np.array in xywh format\n",
    "    pred_bboxes_list: list of (N, 5) np.array in conf+xywh format\n",
    "    \"\"\"\n",
    "    tps, fps, fns = 0, 0, 0\n",
    "    for gt_bboxes, pred_bboxes in zip(gt_bboxes_list, pred_bboxes_list):\n",
    "        tp, fp, fn = calc_is_correct(gt_bboxes, pred_bboxes)\n",
    "        tps += tp\n",
    "        fps += fp\n",
    "        fns += fn\n",
    "        if verbose:\n",
    "            num_gt = len(gt_bboxes)\n",
    "            num_pred = len(pred_bboxes)\n",
    "            print(f'num_gt:{num_gt:<3} num_pred:{num_pred:<3} tp:{tp:<3} fp:{fp:<3} fn:{fn:<3}')\n",
    "            \n",
    "    print(f'tps:{tps}  fp:{fps}  fn:{fns}')\n",
    "    return f_beta(tps, fps, fns, beta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859e47cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(ckpt_path, conf=None, iou=None, max_det=None):\n",
    "    model = torch.hub.load('./',\n",
    "                           'custom',\n",
    "                           path=ckpt_path,\n",
    "                           source='local',\n",
    "                           force_reload=True)  # local repo\n",
    "    if conf is not None:\n",
    "        model.conf = conf  # NMS confidence threshold\n",
    "    if iou is not None:\n",
    "        model.iou  = iou  # NMS IoU threshold\n",
    "    model.classes = None   # (optional list) filter by class, i.e. = [0, 15, 16] for persons, cats and dogs\n",
    "    model.multi_label = False  # NMS multiple labels per box\n",
    "    if model.max_det is not None:\n",
    "        model.max_det = max_det  # maximum number of detections per image\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model, img, conf, size=768, augment=False):\n",
    "    height, width = img.shape[:2]\n",
    "    results = model(img, size=size, augment=augment)  # custom inference size\n",
    "    preds   = results.pandas().xyxy[0]\n",
    "    bboxes  = preds[['xmin','ymin','xmax','ymax']].values\n",
    "    if len(bboxes):\n",
    "        bboxes  = voc2coco(bboxes,height,width).astype(int)\n",
    "        confs   = preds.confidence.values\n",
    "        keep = confs > conf\n",
    "        return bboxes[keep], confs[keep]\n",
    "    else:\n",
    "        return [],[]\n",
    "\n",
    "    \n",
    "def tracking_function(tracker, frame_id, bboxes, scores):\n",
    "    \n",
    "    detects = []\n",
    "    predictions = []\n",
    "    track_bboxes = []\n",
    "    track_scores = []\n",
    "    \n",
    "    if len(scores)>0:\n",
    "        for i in range(len(bboxes)):\n",
    "            box = bboxes[i]\n",
    "            score = scores[i]\n",
    "            x_min = int(box[0])\n",
    "            y_min = int(box[1])\n",
    "            bbox_width = int(box[2])\n",
    "            bbox_height = int(box[3])\n",
    "            detects.append([x_min, y_min, x_min+bbox_width, y_min+bbox_height, score])\n",
    "#            predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "#             print(predictions[:-1])\n",
    "    # Update tracks using detects from current frame\n",
    "    tracked_objects = tracker.update(detections=to_norfair(detects, frame_id))\n",
    "    for tobj in tracked_objects:\n",
    "        bbox_width, bbox_height, last_detected_frame_id = tobj.last_detection.data\n",
    "        if last_detected_frame_id == frame_id:  # Skip objects that were detected on current frame\n",
    "            continue\n",
    "        # Add objects that have no detections on current frame to predictions\n",
    "        xc, yc = tobj.estimate[0]\n",
    "        x_min, y_min = int(round(xc - bbox_width / 2)), int(round(yc - bbox_height / 2))\n",
    "        score = tobj.last_detection.scores[0]\n",
    "        track_bboxes.append([x_min, y_min, bbox_width, bbox_height])\n",
    "        track_scores.append(score)\n",
    "#        predictions.append('{:.2f} {} {} {} {}'.format(score, x_min, y_min, bbox_width, bbox_height))\n",
    "    try:\n",
    "        if len(track_scores) == 0:\n",
    "            return bboxes, scores\n",
    "        if len(scores) == 0:\n",
    "            return np.array(track_bboxes), np.array(track_scores)\n",
    "\n",
    "        bboxes = np.concatenate([bboxes, np.array(track_bboxes)], 0)\n",
    "        scores = np.concatenate([scores, np.array(track_scores)], 0)\n",
    "    except:\n",
    "        print(bboxes, track_bboxes, scores, track_scores)\n",
    "    return bboxes, scores\n",
    "    \n",
    "def format_prediction(bboxes, confs):\n",
    "    annot = ''\n",
    "    if len(bboxes)>0:\n",
    "        for idx in range(len(bboxes)):\n",
    "            xmin, ymin, w, h = bboxes[idx]\n",
    "            conf             = confs[idx]\n",
    "            annot += f'{conf} {xmin} {ymin} {w} {h}'\n",
    "            annot +=' '\n",
    "        annot = annot.strip(' ')\n",
    "    return annot\n",
    "\n",
    "def show_img(img, bboxes, name, color, bbox_format='yolo'):\n",
    "    names  = [name]*len(bboxes)\n",
    "    labels = [0]*len(bboxes)\n",
    "    img    = draw_bboxes(img = img,\n",
    "                           bboxes = bboxes, \n",
    "                           classes = names,\n",
    "                           class_ids = labels,\n",
    "                           class_name = True, \n",
    "                           colors = color, \n",
    "                           bbox_format = bbox_format,\n",
    "                           line_thickness = 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fc93bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(detection, tracked_object):\n",
    "    return np.linalg.norm(detection.points - tracked_object.estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "206f7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_f2_score_v2(gt_bboxes_list, pred_bboxes_list, verbose=False):\n",
    "    \"\"\"\n",
    "    gt_bboxes_list: list of (N, 4) np.array in xywh format\n",
    "    pred_bboxes_list: list of (N, 5) np.array in conf+xywh format\n",
    "    \"\"\"\n",
    "    tps, fps, fns = 0, 0, 0\n",
    "    for gt_bboxes, pred_bboxes in zip(gt_bboxes_list, pred_bboxes_list):\n",
    "        tp, fp, fn = calc_is_correct(gt_bboxes, pred_bboxes)\n",
    "        tps += tp\n",
    "        fps += fp\n",
    "        fns += fn\n",
    "        if verbose:\n",
    "            num_gt = len(gt_bboxes)\n",
    "            num_pred = len(pred_bboxes)\n",
    "            print(f'num_gt:{num_gt:<3} num_pred:{num_pred:<3} tp:{tp:<3} fp:{fp:<3} fn:{fn:<3}')\n",
    "    \n",
    "    precision = tps/(tps+fps)\n",
    "    recall = tps/(tps+fns)\n",
    "\n",
    "    f2 = f_beta(tps, fps, fns, beta=2)\n",
    "\n",
    "    print(f'tps:{tps}  fps:{fps}  fns:{fns}, p: {precision:.3f}, r: {recall:.3f}, f2: {f2:.3f}')\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09a177db",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = (np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "c2 = (np.random.randint(255), np.random.randint(255), np.random.randint(255))\n",
    "\n",
    "\n",
    "def evaluate(model, tracker, df, **kw):\n",
    "    # output video config\n",
    "    frame_id = 0\n",
    "    fps = 24 # don't know exact value\n",
    "    width = 1280\n",
    "    height = 720\n",
    "    video_path = ROOT+\"/output.mp4\"\n",
    "    output_video = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*\"MP4V\"), fps, (1280, height))\n",
    "    \n",
    "    gt_bbox_list = []\n",
    "    pr_bbox_list = []\n",
    "    pr_conf_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        image = load_image(row.image_path)\n",
    "        pred_bbox, pred_conf = predict(model, image, INFER_CONF, IMG_SIZE, AUGMENT)\n",
    "        if tracker is not None:\n",
    "            pred_bbox, pred_conf = tracking_function(tracker, frame_id, pred_bbox, pred_conf)\n",
    "        if len(pred_conf) > 0:\n",
    "            pred = np.concatenate((pred_conf[..., None], pred_bbox), axis=1)\n",
    "        else:\n",
    "            pred = np.array([])\n",
    "            \n",
    "        gt = np.array(row.bboxes)\n",
    "        gt_bbox_list.append(gt)\n",
    "        pr_bbox_list.append(pred)\n",
    "        \n",
    "        pr_conf_list.append(pred_conf)\n",
    "        \n",
    "        img = load_image(row.image_path)\n",
    "        plt.figure(figsize=(16, 12))\n",
    "        img = show_img(img, pred_bbox, 'PRED', c1, 'coco')\n",
    "        img = show_img(img, gt, 'GT', c2, 'coco')\n",
    "        output_video.write(img)\n",
    "        plt.close()\n",
    "        frame_id += 1\n",
    "        #if i > 100:\n",
    "        #    break\n",
    "\n",
    "    # perform iou and conf search for best f2\n",
    "    \n",
    "    \n",
    "    score = calc_f2_score_v2(gt_bbox_list, pr_bbox_list, verbose=False)\n",
    "    print(f\"F2 score {score: .5f}\")\n",
    "    print(f\"Video save in {video_path}\")\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cde58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA  = '../input/yolov5_video2/train.csv'\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "df = pd.read_csv(DATA)\n",
    "df['annotations'] = df['annotations'].apply(lambda x: ast.literal_eval(x))\n",
    "df['num_bbox'] = df['annotations'].apply(lambda x: len(x))\n",
    "val = df[df.fold == 'val'].reset_index(drop=True)\n",
    "val['bboxes'] = val['bboxes'].apply(eval)\n",
    "val = val.sort_values(['video_id', 'video_frame'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe8b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 4b1ec65 torch 1.9.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 280 layers, 12308200 parameters, 0 gradients, 16.2 GFLOPs\n",
      "Adding AutoShape... \n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tps:19891  fps:7113  fns:6188, p: 0.737, r: 0.763, f2: 0.757\n",
      "F2 score  0.75735\n",
      "Video save in cv//output.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7573484617727688"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT  = 'cv/'\n",
    "Path(ROOT).mkdir(exist_ok=True, parents=True)\n",
    "CKPT_PATH = './starfish/yolov5s6_e5_bs2_img5400_video2_HRv1.1_01-22/weights/best.pt'\n",
    "IMG_SIZE  = 5400\n",
    "NMS_CONF      = 0.01  # 0.25\n",
    "MNS_IOU       = None  # 0.45\n",
    "INFER_CONF = 0.15\n",
    "MAX_DET   = 1000  #1000\n",
    "AUGMENT   = False\n",
    "\n",
    "\n",
    "model = load_model(CKPT_PATH, NMS_CONF, MNS_IOU, MAX_DET)\n",
    "tracker = None\n",
    "\n",
    "evaluate(model, tracker, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "281159a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 4b1ec65 torch 1.9.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 280 layers, 12308200 parameters, 0 gradients, 16.2 GFLOPs\n",
      "Adding AutoShape... \n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tps:19614  fps:5773  fns:6345, p: 0.773, r: 0.756, f2: 0.759\n",
      "F2 score  0.75892\n",
      "Video save in cv//output.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7589206255852287"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT  = 'cv/'\n",
    "Path(ROOT).mkdir(exist_ok=True, parents=True)\n",
    "CKPT_PATH = './starfish/yolov5s6_e5_bs2_img5400_video2_HRv1.1_01-22/weights/best.pt'\n",
    "IMG_SIZE  = 5400\n",
    "NMS_CONF      = 0.01  # 0.25\n",
    "MNS_IOU       = None  # 0.45\n",
    "INFER_CONF = 0.20\n",
    "MAX_DET   = 1000  #1000\n",
    "AUGMENT   = False\n",
    "\n",
    "\n",
    "model = load_model(CKPT_PATH, NMS_CONF, MNS_IOU, MAX_DET)\n",
    "tracker = None\n",
    "\n",
    "evaluate(model, tracker, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f5f19f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 🚀 4b1ec65 torch 1.9.1+cu111 CUDA:0 (NVIDIA GeForce RTX 3090, 24268MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 280 layers, 12308200 parameters, 0 gradients, 16.2 GFLOPs\n",
      "Adding AutoShape... \n",
      "OpenCV: FFMPEG: tag 0x5634504d/'MP4V' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tps:15914  fps:3798  fns:9025, p: 0.807, r: 0.638, f2: 0.666\n",
      "F2 score  0.66604\n",
      "Video save in cv//output.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6660360933471725"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT  = 'cv/'\n",
    "Path(ROOT).mkdir(exist_ok=True, parents=True)\n",
    "CKPT_PATH = './starfish/yolov5s6_e5_bs2_img5400_video2_HRv1.1_01-22/weights/best.pt'\n",
    "IMG_SIZE  = 3000\n",
    "NMS_CONF      = 0.01  # 0.25\n",
    "MNS_IOU       = None  # 0.45\n",
    "INFER_CONF = 0.15\n",
    "MAX_DET   = 1000  #1000\n",
    "AUGMENT   = False\n",
    "\n",
    "\n",
    "model = load_model(CKPT_PATH, NMS_CONF, MNS_IOU, MAX_DET)\n",
    "tracker = None\n",
    "\n",
    "evaluate(model, tracker, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c20ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
